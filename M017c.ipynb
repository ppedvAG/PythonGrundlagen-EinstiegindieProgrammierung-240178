{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7ffd0a6-e143-4be6-afca-23bffacf4a96",
   "metadata": {},
   "source": [
    "## Eigene Umgebung\n",
    "\n",
    "Jede Umgebung ist nur eine Klasse mit Funktionen -> Eigener Prozess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88162bdd-c7e6-4100-b842-8028426a82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40d57c0-76d9-4ad3-9255-0d0cec9cff28",
   "metadata": {},
   "source": [
    "### Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd63246-7311-48c8-9f07-455e5b766f1a",
   "metadata": {},
   "source": [
    "Container für Werte, hat aber keine konkrete Werte, sondern gibt nur an was, in dem Container drin sein könnte\n",
    "\n",
    "Discrete: Beschreibt, das hier X verschiedene Werte enthalten sein können\n",
    "\n",
    "Box: Gibt einen Bereich an, in welchem sich der entsprechende Wert befinden kann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d29554e-77c3-430b-be7a-0a9868e32927",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Discrete(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e52ae5d9-efc3-4692-9c22-132e58c0c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Box(0, 100, shape=(3,), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0870d19-1b71-48b8-b3b8-5791e4ad5a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 59, 26])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06cfc26-48e4-4b7e-997b-558164737098",
   "metadata": {},
   "source": [
    "### Eigene Umgebung\n",
    "\n",
    "Jetzt können wir eine eigene Umgebung definieren\n",
    "\n",
    "Diese muss als Oberklasse die gym.Env Klasse haben und die entsprechenden Methoden implementieren (\\_\\_init__, step, reset, render, close)\n",
    "\n",
    "Aufgaben:\n",
    "\n",
    "- action_space, observation_space definieren\n",
    "- State definieren\n",
    "- Step definieren + Belohnung\n",
    "- Reset definieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0d460af-4ba8-4a67-961e-2e8c8821e53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarDriver(gym.Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(3)  # Die verschiedene Aktionen (Nichts, Bremsen, Beschleunigen)\n",
    "        self.observation_space = Box(0, 100, dtype=np.int8)\n",
    "        self.state = 40 + np.random.randint(-10, 10)  # Startgeschwindigkeit, soll zwischen 45 und 55 liegen\n",
    "        self.drive_length = 60  # Zeitlimit\n",
    "\n",
    "    def step(self, action):\n",
    "        # 0: Nichts (+0km/h)\n",
    "        # 1: Bremsen (-3km/h)\n",
    "        # 2: Beschleunigen (+3km/h)\n",
    "        if action == 1:\n",
    "            self.state -= 3\n",
    "        if action == 2:\n",
    "            self.state += 3\n",
    "\n",
    "        # Belohnung\n",
    "        reward = 0\n",
    "        if self.state >= 45 and self.state <= 55:\n",
    "            reward = 1\n",
    "\n",
    "        self.state += np.random.randint(-1, 1)  # Noise\n",
    "\n",
    "        self.drive_length -= 1\n",
    "        return np.array([self.state], dtype=np.int8), reward, self.drive_length <= 0, False, {}\n",
    "\n",
    "    def reset(self, *, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        self.state = 40 + np.random.randint(-10, 10)  # Startgeschwindigkeit, soll zwischen 45 und 55 liegen\n",
    "        self.drive_length = 60  # Zeitlimit\n",
    "        return (np.array([self.state], dtype=np.int8), {})\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f940036-5928-4dab-a4a9-745fa0affb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CarDriver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a460afce-7ce1-4f52-9e48-971a5cffc15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env, warn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35408ea2-43ae-4ec5-af7d-18cd9b302cae",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95947858-a380-41b7-bb15-c8f621ccb7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchgang 0, Score: 3\n",
      "Durchgang 1, Score: 7\n",
      "Durchgang 2, Score: 18\n",
      "Durchgang 3, Score: 0\n",
      "Durchgang 4, Score: 3\n",
      "Durchgang 5, Score: 4\n",
      "Durchgang 6, Score: 0\n",
      "Durchgang 7, Score: 0\n",
      "Durchgang 8, Score: 0\n",
      "Durchgang 9, Score: 0\n"
     ]
    }
   ],
   "source": [
    "durchgaenge = 10\n",
    "for x in range(durchgaenge):\n",
    "    state = env.reset()  # Am Anfang von jedem Durchgang die Umgebung zurücksetzen\n",
    "    score = 0  # Zähler für Belohnungen\n",
    "    done = False  # Zeigt ob der Agent noch im Spiel ist\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()  # Random Action aus dem Action Space entnehmen\n",
    "        state, reward, done, term, info = env.step(action)\n",
    "        # state: Der Status des Spiels (Variablen)\n",
    "        # reward: Belohnung dieses steps\n",
    "        # done, term: Beendet das Spiel\n",
    "        # info: Extra Daten (falls vorhanden)\n",
    "        score += reward\n",
    "\n",
    "    print(f\"Durchgang {x}, Score: {score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc5329-7a00-4f3a-b837-ffed938152a2",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "49758f4d-fc2c-4d16-aecd-fca209a0a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CarDriver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "53624155-0d9d-46b8-82d8-f5369d840348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e8935e27-2e75-4f11-a564-49cab411eab3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 60       |\n",
      "|    ep_rew_mean     | 39.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 905      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 37.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 433          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031332034 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.851       |\n",
      "|    explained_variance   | 0.243        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 24.3         |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 52.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 37          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005077257 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.869      |\n",
      "|    explained_variance   | 0.0026      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | 0.000355    |\n",
      "|    value_loss           | 61          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 37.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 372         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008704567 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.855      |\n",
      "|    explained_variance   | -0.0469     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 40.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 372          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028728675 |\n",
      "|    clip_fraction        | 0.064        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.823       |\n",
      "|    explained_variance   | -0.00894     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31           |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | 0.000902     |\n",
      "|    value_loss           | 60           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 41.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 373          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 32           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055756094 |\n",
      "|    clip_fraction        | 0.0707       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.801       |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28.9         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | 0.00357      |\n",
      "|    value_loss           | 64.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 43.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 373         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008788424 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.78       |\n",
      "|    explained_variance   | 0.0183      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | 0.000831    |\n",
      "|    value_loss           | 73.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 43.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005772254 |\n",
      "|    clip_fraction        | 0.0976      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.699      |\n",
      "|    explained_variance   | 0.0454      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | 0.000482    |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 44.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013820693 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.0174      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | 0.00352     |\n",
      "|    value_loss           | 74.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 44.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 375          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116083175 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.625       |\n",
      "|    explained_variance   | 0.209        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 25.6         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | 0.000479     |\n",
      "|    value_loss           | 63.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 45.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 376          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048514246 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.63        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.3         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    value_loss           | 67.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 46.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 374          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044701407 |\n",
      "|    clip_fraction        | 0.0839       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.644       |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 26.7         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | 0.000863     |\n",
      "|    value_loss           | 70.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 44.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 374         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012697765 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.652      |\n",
      "|    explained_variance   | -0.0207     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.3        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | 0.00779     |\n",
      "|    value_loss           | 77.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 44.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008206104 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.606      |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    value_loss           | 60          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 44.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029608548 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.59       |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | 0.00338     |\n",
      "|    value_loss           | 74.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 43.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 376        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 87         |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08731591 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.54      |\n",
      "|    explained_variance   | 0.358      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.3       |\n",
      "|    n_updates            | 400        |\n",
      "|    policy_gradient_loss | 0.0071     |\n",
      "|    value_loss           | 66.5       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 44.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 376          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043281806 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.64        |\n",
      "|    explained_variance   | -0.0168      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.9         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | 0.00065      |\n",
      "|    value_loss           | 86.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 44.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 376          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029013823 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.596       |\n",
      "|    explained_variance   | 0.0408       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.9         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | 0.00531      |\n",
      "|    value_loss           | 80.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 46.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 376          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048043504 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.615       |\n",
      "|    explained_variance   | -0.0025      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.2         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | 0.00193      |\n",
      "|    value_loss           | 78.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 60           |\n",
      "|    ep_rew_mean          | 47.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 377          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014163131 |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.598       |\n",
      "|    explained_variance   | 0.0211       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.4         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | 0.00288      |\n",
      "|    value_loss           | 79.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 49.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 377         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001138732 |\n",
      "|    clip_fraction        | 0.0471      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.0862      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.00112     |\n",
      "|    value_loss           | 76.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60         |\n",
      "|    ep_rew_mean          | 47.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 377        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 119        |\n",
      "|    total_timesteps      | 45056      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00553234 |\n",
      "|    clip_fraction        | 0.098      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.597     |\n",
      "|    explained_variance   | 0.0715     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.6       |\n",
      "|    n_updates            | 460        |\n",
      "|    policy_gradient_loss | 0.00488    |\n",
      "|    value_loss           | 81.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 39.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 375         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008078982 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.631      |\n",
      "|    explained_variance   | -0.00312    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | 0.00339     |\n",
      "|    value_loss           | 83          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 35.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 130         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007922189 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | -0.0289     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00034    |\n",
      "|    value_loss           | 73.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 60          |\n",
      "|    ep_rew_mean          | 34.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 376         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004180057 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.566      |\n",
      "|    explained_variance   | 0.00304     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | 0.00223     |\n",
      "|    value_loss           | 67.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2043ca7d1c0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d5156a4-9807-470a-9722-eb42574379fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Models/CarDriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cf667423-87b7-4d03-a6b0-a11c341d29fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "env = CarDriver()\n",
    "model = PPO.load(\"Models/CarDriver\", env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f7f26c77-6855-415d-a4ee-27c812aeba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durchgang 0, Score: 56\n",
      "Durchgang 1, Score: 54\n",
      "Durchgang 2, Score: 51\n",
      "Durchgang 3, Score: 46\n",
      "Durchgang 4, Score: 60\n"
     ]
    }
   ],
   "source": [
    "durchgaenge = 5\n",
    "for x in range(durchgaenge):\n",
    "    state = env.reset()  # Am Anfang von jedem Durchgang die Umgebung zurücksetzen\n",
    "    score = 0  # Zähler für Belohnungen\n",
    "    done = False  # Zeigt ob der Agent noch im Spiel ist\n",
    "    state = state[0]\n",
    "\n",
    "    while not (done or term):\n",
    "        # env.render()\n",
    "        action, _ = model.predict(state)  # Random Action aus dem Action Space entnehmen\n",
    "        if action.ndim == 1:\n",
    "            action = action[0]\n",
    "        \n",
    "        state, reward, done, term, info = env.step(action)\n",
    "        # state: Der Status des Spiels (Variablen)\n",
    "        # reward: Belohnung dieses steps\n",
    "        # done, term: Beendet das Spiel\n",
    "        # info: Extra Daten (falls vorhanden)\n",
    "        score += reward\n",
    "\n",
    "    print(f\"Durchgang {x}, Score: {score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b57ee-be1f-4597-9da4-0d48a7e4e92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
